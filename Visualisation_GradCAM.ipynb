{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from brainiac.loader import ADNIClassificationDataset\n",
    "from brainiac.utils import load_model\n",
    "from brainiac.models import SimpleCNN\n",
    "from brainiac.grad_cam import GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/basimova_nf/ADNI-processed/data.csv')\n",
    "dataset = ADNIClassificationDataset(df)\n",
    "\n",
    "images = dataset[0][0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_3d_img_to_frames(img):\n",
    "    img = img.squeeze(0).squeeze(0)\n",
    "    frames = [Image.fromarray(np.uint8(img.numpy()[i] * 255)) for i in range(img.shape[0])]\n",
    "    frames = [fr.convert('P', palette = Image.ADAPTIVE) for fr in frames]\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gif(images, path, duration=0.1):\n",
    "    images[0].save(path, save_all=True, append_images=images[1:],\n",
    "                   optimize=False, duration=duration, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "model, _ = load_model(model, 'trained_model/CNN/CN-MCI-AD_Adam_10_4_0.0001_1e-05/model_epoch8.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regions_from(model, images, target_layers):\n",
    "    \n",
    "    target_layers = ['conv', 'pool']\n",
    "    target_class = 0\n",
    "\n",
    "    gcam = GradCAM(model, target_layers, mode='3D')\n",
    "    \n",
    "    _ = gcam.forward(images)\n",
    "    \n",
    "    ids_ = torch.LongTensor([[target_class]] * len(images))\n",
    "    gcam.backward(ids=ids_)\n",
    "    \n",
    "    regions = gcam.generate(target_layer=target_layers[-1])\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = make_regions_from(model, images, ['conv', 'pool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcam = (regions + images) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 96, 96])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = from_3d_img_to_frames(gcam)\n",
    "save_gif(frames, 'out.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
