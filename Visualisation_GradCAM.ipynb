{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from brainiac.loader import ADNIClassificationDataset\n",
    "from brainiac.utils import load_model\n",
    "from brainiac.models import *\n",
    "from brainiac.grad_cam import GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_3d_img_to_frames(img):\n",
    "    img = img.squeeze(0).squeeze(0)\n",
    "    frames = [Image.fromarray(np.uint8(img.numpy()[i] * 255)) for i in range(img.shape[0])]\n",
    "    frames = [fr.convert('P', palette = Image.ADAPTIVE) for fr in frames]\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gif(images, path, duration=0.1):\n",
    "    images[0].save(path, save_all=True, append_images=images[1:],\n",
    "                   optimize=False, duration=duration, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regions_from(model, images, target_layers, target_class=None, mode='3D'):\n",
    "    \n",
    "    gcam = GradCAM(model, target_layers, mode=mode)\n",
    "    \n",
    "    probs, ids = gcam.forward(images)\n",
    "    \n",
    "    if target_class is None:\n",
    "        target_class = ids[0, 0]\n",
    "        \n",
    "    ids_ = torch.LongTensor([[target_class]] * len(images))\n",
    "    gcam.backward(ids=ids_)\n",
    "    \n",
    "    regions = gcam.generate(target_layer=target_layers[-1])\n",
    "    \n",
    "    gcam.remove_hook()\n",
    "    \n",
    "    regions[regions < 0.2] = 0\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradcam(gcam, raw_image, paper_cmap=False):\n",
    "    gcam = gcam.cpu().numpy()\n",
    "    cmap = cm.jet_r(gcam)[..., :3] * 255.0\n",
    "    if paper_cmap:\n",
    "        alpha = gcam[..., None]\n",
    "        gcam = alpha * cmap + (1 - alpha) * raw_image\n",
    "    else:\n",
    "        gcam = (cmap.astype(np.float) + raw_image.astype(np.float)) / 2\n",
    "     \n",
    "    return np.uint8(gcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../ADNI-processed/data.csv'\n",
    "images_path = '../ADNI-processed/images/'\n",
    "df = pd.read_csv(path)\n",
    "idx = 1008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ADNIClassificationDataset(df, images_path=images_path)\n",
    "\n",
    "raw_image = np.uint8(dataset[idx][0][0] * 255)\n",
    "raw_image = [cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) for img in raw_image]\n",
    "\n",
    "images = dataset[idx][0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet152(num_classes=2)\n",
    "# model, _ = load_model(model, 'trained_model/ResNet152/classes-CN-AD_optim-Adam_aug-1_sampling-1_lr-5e-05_scheduler-0_pretrain-1/model_epoch199.pth')\n",
    "# _ = model.eval()\n",
    "\n",
    "model = resnet50(num_classes=2)\n",
    "model, _ = load_model(model, 'trained_model/ResNet50/classes-CN-AD_optim-Adam_aug-1_sampling-1_lr-0.001_scheduler-0_pretrain-1/model_epoch151.pth')\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'layer1'\n",
    "regions = make_regions_from(model, images, target_layers=[layer_name], target_class=1, mode='3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "\n",
    "i = 90\n",
    "raw_image = cv2.cvtColor(np.uint8(images[0, 0, i, :, :] * 255), cv2.COLOR_GRAY2RGB)\n",
    "gcam = get_gradcam(1 - regions[0, 0, i], raw_image)\n",
    "gcam = cv2.resize(gcam, (96, 96))\n",
    "ax[0].imshow(np.rot90(gcam))\n",
    "ax[0].axis('off')\n",
    "\n",
    "i = 53\n",
    "raw_image = cv2.cvtColor(np.uint8(images[0, 0, :, i, :] * 255), cv2.COLOR_GRAY2RGB)\n",
    "gcam = get_gradcam(1 - regions[0, 0, :, i, :], raw_image)\n",
    "gcam = cv2.resize(gcam, (96, 96))\n",
    "ax[1].imshow(np.rot90(gcam))\n",
    "ax[1].axis('off')\n",
    "\n",
    "i = 54\n",
    "raw_image = cv2.cvtColor(np.uint8(images[0, 0, :, :, i] * 255), cv2.COLOR_GRAY2RGB)\n",
    "gcam = get_gradcam(1 - regions[0, 0, :, :, i], raw_image)\n",
    "gcam = cv2.resize(gcam, (96, 96))\n",
    "ax[2].imshow(np.rot90(gcam))\n",
    "ax[2].axis('off')\n",
    "\n",
    "# plt.savefig('pics/gradcam.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../ADNI_cut/data.csv'\n",
    "images_path = '../ADNI_cut/images/'\n",
    "df = pd.read_csv(path)\n",
    "idx = 1008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ADNIClassificationDataset(df, images_path=images_path)\n",
    "\n",
    "raw_image = np.uint8(dataset[idx][0][0] * 255)\n",
    "raw_image = [cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) for img in raw_image]\n",
    "\n",
    "images = dataset[idx][0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet152(num_classes=2)\n",
    "model, _ = load_model(model, 'trained_model/ResNet152/pretrain_resnet.pth')\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'layer2'\n",
    "regions = make_regions_from(model, images, target_layers=[layer_name], target_class=1, mode='3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "\n",
    "i = 40\n",
    "raw_image = cv2.cvtColor(np.uint8(images[0, 0, i, :, :] * 255), cv2.COLOR_GRAY2RGB)\n",
    "gcam = get_gradcam(1 - regions[0, 0, i], raw_image)\n",
    "gcam = cv2.resize(gcam, (96, 96))\n",
    "ax[0].imshow(np.rot90(gcam))\n",
    "ax[0].axis('off')\n",
    "\n",
    "i = 54\n",
    "raw_image = cv2.cvtColor(np.uint8(images[0, 0, :, i, :] * 255), cv2.COLOR_GRAY2RGB)\n",
    "gcam = get_gradcam(1 - regions[0, 0, :, i, :], raw_image)\n",
    "gcam = cv2.resize(gcam, (96, 96))\n",
    "ax[1].imshow(np.rot90(gcam))\n",
    "ax[1].axis('off')\n",
    "\n",
    "i = 66\n",
    "raw_image = cv2.cvtColor(np.uint8(images[0, 0, :, :, i] * 255), cv2.COLOR_GRAY2RGB)\n",
    "gcam = get_gradcam(1 - regions[0, 0, :, :, i], raw_image)\n",
    "gcam = cv2.resize(gcam, (96, 96))\n",
    "ax[2].imshow(np.rot90(gcam))\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.savefig('pics/gradcam.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = []\n",
    "for i in list(range(0, 128)) + list(reversed(range(0, 128))):\n",
    "    raw_image = cv2.cvtColor(np.uint8(images[0, 0, i, :, :] * 255), cv2.COLOR_GRAY2RGB)\n",
    "    gcam = get_gradcam(1 - regions[0, 0, i, :, :], raw_image)\n",
    "    gcam = np.rot90(cv2.resize(gcam, (128, 128)))\n",
    "    gif.append(Image.fromarray(gcam))\n",
    "save_gif(gif, 'pics/gradcam_gif_1.gif')\n",
    "\n",
    "gif = []\n",
    "for i in list(range(15, 80)) + list(reversed(range(15, 80))):\n",
    "    raw_image = cv2.cvtColor(np.uint8(images[0, 0, :, i, :] * 255), cv2.COLOR_GRAY2RGB)\n",
    "    gcam = get_gradcam(1 - regions[0, 0, :, i, :], raw_image)\n",
    "    gcam = np.rot90(cv2.resize(gcam, (128, 128)))\n",
    "    gif.append(Image.fromarray(gcam))\n",
    "save_gif(gif, 'pics/gradcam_gif_2.gif')\n",
    "\n",
    "gif = []\n",
    "for i in list(range(15, 83)) + list(reversed(range(15, 83))):\n",
    "    raw_image = cv2.cvtColor(np.uint8(images[0, 0, :, :, i] * 255), cv2.COLOR_GRAY2RGB)\n",
    "    gcam = get_gradcam(1 - regions[0, 0, :, :, i], raw_image)\n",
    "    gcam = np.rot90(cv2.resize(gcam, (128, 128)))\n",
    "    gif.append(Image.fromarray(gcam))\n",
    "save_gif(gif, 'pics/gradcam_gif_3.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
